{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93ec5aca-6829-49d3-8ce3-f2b383ab49ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.fft as fft\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from einops import rearrange, reduce, repeat\n",
    "from scipy.fftpack import next_fast_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "069a78e1-fe1e-43d8-b0af-e587b57d96e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exponential smoothing\n",
    "\n",
    "def conv1d_fft(f, g, dim=-1):\n",
    "    N = f.size(dim)\n",
    "    M = g.size(dim)\n",
    "\n",
    "    fast_len = next_fast_len(N + M - 1)\n",
    "\n",
    "    F_f = fft.rfft(f, fast_len, dim=dim)\n",
    "    F_g = fft.rfft(g, fast_len, dim=dim)\n",
    "\n",
    "    F_fg = F_f * F_g.conj()\n",
    "    out = fft.irfft(F_fg, fast_len, dim=dim)\n",
    "    out = out.roll((-1,), dims=(dim,))\n",
    "    idx = torch.as_tensor(range(fast_len - N, fast_len)).to(out.device)\n",
    "    out = out.index_select(dim, idx)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "class ExponentialSmoothing(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, nhead, dropout=0.1, aux=False):\n",
    "        super().__init__()\n",
    "        self._smoothing_weight = nn.Parameter(torch.randn(nhead, 1))\n",
    "        self.v0 = nn.Parameter(torch.randn(1, 1, nhead, dim))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        if aux:\n",
    "            self.aux_dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, values, aux_values=None):\n",
    "        b, t, h, d = values.shape\n",
    "\n",
    "        init_weight, weight = self.get_exponential_weight(t)\n",
    "        output = conv1d_fft(self.dropout(values), weight, dim=1)\n",
    "        output = init_weight * self.v0 + output\n",
    "\n",
    "        if aux_values is not None:\n",
    "            aux_weight = weight / (1 - self.weight) * self.weight\n",
    "            aux_output = conv1d_fft(self.aux_dropout(aux_values), aux_weight)\n",
    "            output = output + aux_output\n",
    "\n",
    "        return output\n",
    "\n",
    "    def get_exponential_weight(self, T):\n",
    "        # Generate array [0, 1, ..., T-1]\n",
    "        powers = torch.arange(T, dtype=torch.float, device=self.weight.device)\n",
    "\n",
    "        # (1 - \\alpha) * \\alpha^t, for all t = T-1, T-2, ..., 0]\n",
    "        weight = (1 - self.weight) * (self.weight ** torch.flip(powers, dims=(0,)))\n",
    "\n",
    "        # \\alpha^t for all t = 1, 2, ..., T\n",
    "        init_weight = self.weight ** (powers + 1)\n",
    "\n",
    "        return rearrange(init_weight, 'h t -> () t h ()'), \\\n",
    "               rearrange(weight, 'h t -> () t h ()')\n",
    "\n",
    "    @property\n",
    "    def weight(self):\n",
    "        return torch.sigmoid(self._smoothing_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd4673de-6ca5-41db-aa10-5d32a97b9ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding layer\n",
    "class ETSEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                              kernel_size=3, padding=2, bias=False)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        nn.init.kaiming_normal_(self.conv.weight)\n",
    "\n",
    "    def forward(self, x,):\n",
    "        x = self.conv(x.permute(0,2,1))[..., :-2]\n",
    "        return self.dropout(x.transpose(1,2))\n",
    "\n",
    "\n",
    "class Feedforward(nn.Module):\n",
    "    def __init__(self, d_model, dim_feedforward, dropout=0.1, activation='sigmoid'):\n",
    "        # Implementation of Feedforward model\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward, bias=False)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model, bias=False)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.activation = getattr(F, activation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear2(self.dropout1(self.activation(self.linear1(x))))\n",
    "        return self.dropout2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f69290a3-d9d5-4878-a698-5d0107e2098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder\n",
    "class DampingLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, pred_len, nhead, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.pred_len = pred_len\n",
    "        self.nhead = nhead\n",
    "        self._damping_factor = nn.Parameter(torch.randn(1, nhead))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = repeat(x, 'b 1 d -> b t d', t=self.pred_len)\n",
    "        b, t, d = x.shape\n",
    "\n",
    "        powers = torch.arange(self.pred_len).to(self._damping_factor.device) + 1\n",
    "        powers = powers.view(self.pred_len, 1)\n",
    "        damping_factors = self.damping_factor ** powers\n",
    "        damping_factors = damping_factors.cumsum(dim=0)\n",
    "        x = x.view(b, t, self.nhead, -1)\n",
    "        x = self.dropout(x) * damping_factors.unsqueeze(-1)\n",
    "        return x.view(b, t, d)\n",
    "\n",
    "    @property\n",
    "    def damping_factor(self):\n",
    "        return torch.sigmoid(self._damping_factor)\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, nhead, c_out, pred_len, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "        self.c_out = c_out\n",
    "        self.pred_len = pred_len\n",
    "\n",
    "        self.growth_damping = DampingLayer(pred_len, nhead, dropout=dropout)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, growth, season):\n",
    "        growth_horizon = self.growth_damping(growth[:, -1:])\n",
    "        growth_horizon = self.dropout1(growth_horizon)\n",
    "\n",
    "        seasonal_horizon = season[:, -self.pred_len:]\n",
    "        return growth_horizon, seasonal_horizon\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.d_model = layers[0].d_model\n",
    "        self.c_out = layers[0].c_out\n",
    "        self.pred_len = layers[0].pred_len\n",
    "        self.nhead = layers[0].nhead\n",
    "\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.pred = nn.Linear(self.d_model, self.c_out)\n",
    "\n",
    "    def forward(self, growths, seasons):\n",
    "        growth_repr = []\n",
    "        season_repr = []\n",
    "\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            growth_horizon, season_horizon = layer(growths[idx], seasons[idx])\n",
    "            growth_repr.append(growth_horizon)\n",
    "            season_repr.append(season_horizon)\n",
    "        growth_repr = sum(growth_repr)\n",
    "        season_repr = sum(season_repr)\n",
    "        return self.pred(growth_repr), self.pred(season_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b2fe9f3-ca23-4d67-9d75-78344b677224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder\n",
    "class GrowthLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, nhead, d_head=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_head = d_head or (d_model // nhead)\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "\n",
    "        self.z0 = nn.Parameter(torch.randn(self.nhead, self.d_head))\n",
    "        self.in_proj = nn.Linear(self.d_model, self.d_head * self.nhead)\n",
    "        self.es = ExponentialSmoothing(self.d_head, self.nhead, dropout=dropout)\n",
    "        self.out_proj = nn.Linear(self.d_head * self.nhead, self.d_model)\n",
    "\n",
    "        assert self.d_head * self.nhead == self.d_model, \"d_model must be divisible by nhead\"\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        :param inputs: shape: (batch, seq_len, dim)\n",
    "        :return: shape: (batch, seq_len, dim)\n",
    "        \"\"\"\n",
    "        b, t, d = inputs.shape\n",
    "        values = self.in_proj(inputs).view(b, t, self.nhead, -1)\n",
    "        values = torch.cat([repeat(self.z0, 'h d -> b 1 h d', b=b), values], dim=1)\n",
    "        values = values[:, 1:] - values[:, :-1]\n",
    "        out = self.es(values)\n",
    "        out = torch.cat([repeat(self.es.v0, '1 1 h d -> b 1 h d', b=b), out], dim=1)\n",
    "        out = rearrange(out, 'b t h d -> b t (h d)')\n",
    "        return self.out_proj(out)\n",
    "\n",
    "\n",
    "class FourierLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, pred_len, k=None, low_freq=1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.pred_len = pred_len\n",
    "        self.k = k\n",
    "        self.low_freq = low_freq\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"x: (b, t, d)\"\"\"\n",
    "        b, t, d = x.shape\n",
    "        x_freq = fft.rfft(x, dim=1)\n",
    "\n",
    "        if t % 2 == 0:\n",
    "            x_freq = x_freq[:, self.low_freq:-1]\n",
    "            f = fft.rfftfreq(t)[self.low_freq:-1]\n",
    "        else:\n",
    "            x_freq = x_freq[:, self.low_freq:]\n",
    "            f = fft.rfftfreq(t)[self.low_freq:]\n",
    "\n",
    "        x_freq, index_tuple = self.topk_freq(x_freq)\n",
    "        f = repeat(f, 'f -> b f d', b=x_freq.size(0), d=x_freq.size(2))\n",
    "        f = rearrange(f[index_tuple], 'b f d -> b f () d').to(x_freq.device)\n",
    "\n",
    "        return self.extrapolate(x_freq, f, t)\n",
    "\n",
    "    def extrapolate(self, x_freq, f, t):\n",
    "        x_freq = torch.cat([x_freq, x_freq.conj()], dim=1)\n",
    "        f = torch.cat([f, -f], dim=1)\n",
    "        t_val = rearrange(torch.arange(t + self.pred_len, dtype=torch.float),\n",
    "                      't -> () () t ()').to(x_freq.device)\n",
    "\n",
    "        amp = rearrange(x_freq.abs() / t, 'b f d -> b f () d')\n",
    "        phase = rearrange(x_freq.angle(), 'b f d -> b f () d')\n",
    "\n",
    "        x_time = amp * torch.cos(2 * math.pi * f * t_val + phase)\n",
    "\n",
    "        return reduce(x_time, 'b f t d -> b t d', 'sum')\n",
    "\n",
    "    def topk_freq(self, x_freq):\n",
    "        values, indices = torch.topk(x_freq.abs(), self.k, dim=1, largest=True, sorted=True)\n",
    "        mesh_a, mesh_b = torch.meshgrid(torch.arange(x_freq.size(0)), torch.arange(x_freq.size(2)))\n",
    "        index_tuple = (mesh_a.unsqueeze(1), indices, mesh_b.unsqueeze(1))\n",
    "        x_freq = x_freq[index_tuple]\n",
    "\n",
    "        return x_freq, index_tuple\n",
    "\n",
    "\n",
    "class LevelLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, c_out, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.c_out = c_out\n",
    "\n",
    "        self.es = ExponentialSmoothing(1, self.c_out, dropout=dropout, aux=True)\n",
    "        self.growth_pred = nn.Linear(self.d_model, self.c_out)\n",
    "        self.level_pred = nn.Linear(862, self.c_out)\n",
    "        self.season_pred = nn.Linear(self.d_model, self.c_out)\n",
    "\n",
    "    def forward(self, level, growth, season):\n",
    "        b, t, f = level.shape\n",
    "        growth = self.growth_pred(growth).view(b, t, self.c_out, 1)\n",
    "        season = self.season_pred(season).view(b, t, self.c_out, 1)\n",
    "        growth = growth.view(b, t, self.c_out, 1)\n",
    "        season = season.view(b, t, self.c_out, 1)\n",
    "        if f == 862:\n",
    "            level = self.level_pred(level).view(b, t, self.c_out, 1)\n",
    "        else:\n",
    "            level = level.view(b, t, self.c_out, 1)\n",
    "        out = self.es(level - season, aux_values=growth)\n",
    "        out = rearrange(out, 'b t h d -> b t (h d)')\n",
    "        return out\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, nhead, c_out, seq_len, pred_len, k, dim_feedforward=None, dropout=0.1,\n",
    "                 activation='sigmoid', layer_norm_eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "        self.c_out = c_out\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        dim_feedforward = dim_feedforward or 4 * d_model\n",
    "        self.dim_feedforward = dim_feedforward\n",
    "\n",
    "        self.growth_layer = GrowthLayer(d_model, nhead, dropout=dropout)\n",
    "        self.seasonal_layer = FourierLayer(d_model, pred_len, k=k)\n",
    "        self.level_layer = LevelLayer(d_model, c_out, dropout=dropout)\n",
    "\n",
    "        # Implementation of Feedforward model\n",
    "        self.ff = Feedforward(d_model, dim_feedforward, dropout=dropout, activation=activation)\n",
    "        self.norm1 = nn.LayerNorm(d_model, eps=layer_norm_eps)\n",
    "        self.norm2 = nn.LayerNorm(d_model, eps=layer_norm_eps)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, res, level, attn_mask=None):\n",
    "        season = self._season_block(res)\n",
    "        res = res - season[:, :-self.pred_len]\n",
    "        growth = self._growth_block(res)\n",
    "        res = self.norm1(res - growth[:, 1:])\n",
    "        res = self.norm2(res + self.ff(res))\n",
    "\n",
    "        level = self.level_layer(level, growth[:, :-1], season[:, :-self.pred_len])\n",
    "\n",
    "        return res, level, growth, season\n",
    "\n",
    "    def _growth_block(self, x):\n",
    "        x = self.growth_layer(x)\n",
    "        return self.dropout1(x)\n",
    "\n",
    "    def _season_block(self, x):\n",
    "        x = self.seasonal_layer(x)\n",
    "        return self.dropout2(x)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, res, level, attn_mask=None):\n",
    "        growths = []\n",
    "        seasons = []\n",
    "        for layer in self.layers:\n",
    "            res, level, growth, season = layer(res, level, attn_mask=None)\n",
    "            growths.append(growth)\n",
    "            seasons.append(season)\n",
    "\n",
    "        return level, growths, seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1426296-0f33-497d-83cf-3a017b2c23d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "\n",
    "class Transform:\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def transform(self, x):\n",
    "        return self.jitter(self.shift(self.scale(x)))\n",
    "\n",
    "    def jitter(self, x):\n",
    "        return x + (torch.randn(x.shape).to(x.device) * self.sigma)\n",
    "\n",
    "    def scale(self, x):\n",
    "        return x * (torch.randn(x.size(-1)).to(x.device) * self.sigma + 1)\n",
    "\n",
    "    def shift(self, x):\n",
    "        return x + (torch.randn(x.size(-1)).to(x.device) * self.sigma)\n",
    "\n",
    "\n",
    "class ETSformer(nn.Module):\n",
    "\n",
    "    def __init__(self, configs):\n",
    "        super().__init__()\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.label_len = configs.label_len\n",
    "        self.pred_len = configs.pred_len\n",
    "\n",
    "        self.configs = configs\n",
    "\n",
    "        assert configs.d_layers == configs.e_layers\n",
    "\n",
    "        # Embedding\n",
    "        self.enc_embedding = ETSEmbedding(configs.enc_in, configs.d_model, dropout=configs.dropout)\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    configs.d_model, configs.n_heads, configs.c_out, configs.seq_len, configs.pred_len, configs.K,\n",
    "                    dim_feedforward=configs.d_ff,\n",
    "                    dropout=configs.dropout,\n",
    "                    activation=configs.activation,\n",
    "                ) for _ in range(configs.e_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    configs.d_model, configs.n_heads, configs.c_out, configs.pred_len,\n",
    "                    dropout=configs.dropout,\n",
    "                ) for _ in range(configs.d_layers)\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        self.transform = Transform(sigma=self.configs.std)\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec,\n",
    "                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n",
    "        with torch.no_grad():\n",
    "            if self.training:\n",
    "                x_enc = self.transform.transform(x_enc)\n",
    "        res = self.enc_embedding(x_enc)\n",
    "        level, growths, seasons = self.encoder(res, x_enc, attn_mask=enc_self_mask)\n",
    "\n",
    "        growth, season = self.decoder(growths, seasons)\n",
    "        preds = level[:, -1:] + growth + season\n",
    "        return preds, level, growths, seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cde7a90-4208-4fd8-8451-7ddd53f4d872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class TimeFeature:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "        pass\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + \"()\"\n",
    "    \n",
    "class SecondOfMinute(TimeFeature):\n",
    "    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "        return index.second / 59.0 - 0.5\n",
    "\n",
    "\n",
    "class MinuteOfHour(TimeFeature):\n",
    "    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "        return index.minute / 59.0 - 0.5\n",
    "\n",
    "\n",
    "class HourOfDay(TimeFeature):\n",
    "    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "        return index.hour / 23.0 - 0.5\n",
    "\n",
    "\n",
    "class DayOfWeek(TimeFeature):\n",
    "    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "        return index.dayofweek / 6.0 - 0.5\n",
    "\n",
    "\n",
    "class DayOfMonth(TimeFeature):\n",
    "    \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "        return (index.day - 1) / 30.0 - 0.5\n",
    "\n",
    "\n",
    "class DayOfYear(TimeFeature):\n",
    "    \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "        return (index.dayofyear - 1) / 365.0 - 0.5\n",
    "\n",
    "\n",
    "class MonthOfYear(TimeFeature):\n",
    "    \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "        return (index.month - 1) / 11.0 - 0.5\n",
    "\n",
    "\n",
    "class WeekOfYear(TimeFeature):\n",
    "    \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "        return (index.isocalendar().week - 1) / 52.0 - 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffa36784-4f35-4a3b-b76e-feb8278a097b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data minute transformer\n",
    "from pandas.tseries import offsets\n",
    "from torch import Tensor\n",
    "from typing import List, Optional\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "\n",
    "\n",
    "def time_features(dates, freq='h'):\n",
    "    return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)])\n",
    "\n",
    "\n",
    "def time_features_from_frequency_str(freq_str: str) -> List[TimeFeature]:\n",
    "    \"\"\"\n",
    "    Returns a list of time features that will be appropriate for the given frequency string.\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_str\n",
    "        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n",
    "    \"\"\"\n",
    "\n",
    "    features_by_offsets = {\n",
    "        offsets.YearEnd: [],\n",
    "        offsets.QuarterEnd: [MonthOfYear],\n",
    "        offsets.MonthEnd: [MonthOfYear],\n",
    "        offsets.Week: [DayOfMonth, WeekOfYear],\n",
    "        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Minute: [\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "        offsets.Second: [\n",
    "            SecondOfMinute,\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    offset = to_offset(freq_str)\n",
    "\n",
    "    for offset_type, feature_classes in features_by_offsets.items():\n",
    "        if isinstance(offset, offset_type):\n",
    "            return [cls() for cls in feature_classes]\n",
    "\n",
    "    supported_freq_msg = f\"\"\"\n",
    "    Unsupported frequency {freq_str}\n",
    "    The following frequencies are supported:\n",
    "        Y   - yearly\n",
    "            alias: A\n",
    "        M   - monthly\n",
    "        W   - weekly\n",
    "        D   - daily\n",
    "        B   - business days\n",
    "        H   - hourly\n",
    "        T   - minutely\n",
    "            alias: min\n",
    "        S   - secondly\n",
    "    \"\"\"\n",
    "    raise RuntimeError(supported_freq_msg)\n",
    "\n",
    "    \n",
    "class Dataset_Custom(Dataset):\n",
    "    def __init__(self, df_name, size=None,\n",
    "                 features='S', target='OT', scale=True, timeenc=0, freq='h'):\n",
    "        # size [seq_len, label_len, pred_len]\n",
    "        # info\n",
    "        self.df_name = df_name\n",
    "        if size == None:\n",
    "            self.seq_len = 24 * 4 * 4\n",
    "            self.label_len = 24 * 4\n",
    "            self.pred_len = 24 * 4\n",
    "        else:\n",
    "            self.seq_len = size[0]\n",
    "            self.label_len = size[1]\n",
    "            self.pred_len = size[2]\n",
    "        # init\n",
    "\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.scale = scale\n",
    "        self.timeenc = timeenc\n",
    "        self.freq = freq\n",
    "\n",
    "        self.__read_data__()\n",
    "\n",
    "    def __read_data__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        df_raw = self.df_name.copy()\n",
    "\n",
    "        '''\n",
    "        df_raw.columns: ['date', ...(other features), target feature]\n",
    "        '''\n",
    "        cols = list(df_raw.columns)\n",
    "        cols.remove(self.target)\n",
    "        cols.remove('date')\n",
    "        df_raw = df_raw[['date'] + cols + [self.target]]\n",
    "        \n",
    "        final_record = len(df_raw) - self.seq_len\n",
    "\n",
    "        if self.features == 'M' or self.features == 'MS':\n",
    "            cols_data = df_raw.columns[1:]\n",
    "            df_data = df_raw[cols_data]\n",
    "        elif self.features == 'S':\n",
    "            df_data = df_raw[[self.target]]\n",
    "\n",
    "        if self.scale:\n",
    "            train_data = df_data[:final_record]\n",
    "            self.scaler.fit(train_data.values)\n",
    "            data = self.scaler.transform(df_data.values)\n",
    "        else:\n",
    "            data = df_data.values\n",
    "        \n",
    "        data_targets = df_data[self.target].values\n",
    "        \n",
    "        \n",
    "\n",
    "        df_stamp = df_raw[['date']][:final_record]\n",
    "        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n",
    "        if self.timeenc == 0:\n",
    "            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
    "            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
    "            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
    "            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
    "            data_stamp = df_stamp.drop(['date'], 1).values\n",
    "        elif self.timeenc == 1:\n",
    "            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
    "            data_stamp = data_stamp.transpose(1, 0)\n",
    "\n",
    "        self.data_x = data[:final_record]\n",
    "        self.data_y = data_targets[:final_record]\n",
    "        self.data_stamp = data_stamp\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        s_begin = index\n",
    "        s_end = s_begin + self.seq_len\n",
    "        r_begin = s_end - self.label_len\n",
    "        r_end = r_begin + self.label_len + self.pred_len\n",
    "\n",
    "        seq_x = self.data_x[s_begin:s_end]\n",
    "        seq_y = self.data_y[r_begin:r_end]\n",
    "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
    "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
    "\n",
    "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        return self.scaler.inverse_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f6681a6-603d-4fa5-b840-38d7b0e7059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        if param_group['name'] == 'smoothing':\n",
    "            continue\n",
    "        elif param_group['name'] == 'damping':\n",
    "            continue\n",
    "        else:\n",
    "            learning_rate = args.learning_rate\n",
    "\n",
    "        if args.lradj == 'exponential':\n",
    "            lr_adjust = {epoch: learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "        elif args.lradj == 'schedule':\n",
    "            lr_adjust = {\n",
    "                2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "                10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "            }\n",
    "        elif args.lradj == 'cos':\n",
    "            lr_adjust = {epoch: learning_rate * 0.5 * (1. + math.cos(math.pi * epoch / args.train_epochs))}\n",
    "        elif args.lradj == 'cos_with_warmup':\n",
    "            if epoch <= args.warmup_epochs:\n",
    "                lr = args.min_lr + (learning_rate - args.min_lr) * (epoch / (args.warmup_epochs + 1))\n",
    "            else:\n",
    "                curr_epoch = epoch - args.warmup_epochs\n",
    "                total_epochs = args.train_epochs - args.warmup_epochs\n",
    "                lr = learning_rate * 0.5 * (1. + math.cos(math.pi * curr_epoch / total_epochs))\n",
    "            lr_adjust = {epoch: lr}\n",
    "        elif args.lradj == 'exponential_with_warmup':\n",
    "            if epoch <= args.warmup_epochs:\n",
    "                lr = args.min_lr + (learning_rate - args.min_lr) * (epoch / (args.warmup_epochs + 1))\n",
    "            else:\n",
    "                curr_epoch = epoch - args.warmup_epochs\n",
    "                lr = learning_rate * (0.5 ** ((curr_epoch - 1) // 1))\n",
    "            lr_adjust = {epoch: lr}\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        if epoch in lr_adjust.keys():\n",
    "            lr = lr_adjust[epoch]\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            print('Updating learning rate to {}'.format(lr))\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model, path):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model, path):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ea5ec19-4c6b-4d23-8d7e-2c3aa35cfcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "def select_optimizer(config, model):\n",
    "    if 'warmup' in config.lradj:\n",
    "        lr = config.min_lr\n",
    "    else:\n",
    "        lr = config.learning_rate\n",
    "\n",
    "    if config.smoothing_learning_rate > 0:\n",
    "        smoothing_lr = config.smoothing_learning_rate\n",
    "    else:\n",
    "        smoothing_lr = 100 * config.learning_rate\n",
    "\n",
    "    if config.damping_learning_rate > 0:\n",
    "        damping_lr = config.damping_learning_rate\n",
    "    else:\n",
    "        damping_lr = 100 * config.learning_rate\n",
    "\n",
    "    nn_params = []\n",
    "    smoothing_params = []\n",
    "    damping_params = []\n",
    "    for k, v in model.named_parameters():\n",
    "        if k[-len('_smoothing_weight'):] == '_smoothing_weight':\n",
    "            smoothing_params.append(v)\n",
    "        elif k[-len('_damping_factor'):] == '_damping_factor':\n",
    "            damping_params.append(v)\n",
    "        else:\n",
    "            nn_params.append(v)\n",
    "\n",
    "    model_optim = Adam([\n",
    "        {'params': nn_params, 'lr': lr, 'name': 'nn'},\n",
    "        {'params': smoothing_params, 'lr': smoothing_lr, 'name': 'smoothing'},\n",
    "        {'params': damping_params, 'lr': damping_lr, 'name': 'damping'},\n",
    "    ])\n",
    "\n",
    "    return model_optim\n",
    "\n",
    "def select_criterion():\n",
    "    criterion = nn.MSELoss()\n",
    "    return criterion\n",
    "\n",
    "def run_iteration(model, batch_x, batch_y, batch_x_mark, batch_y_mark, device, configs):\n",
    "        batch_x = batch_x.float().to(device)\n",
    "        batch_y = batch_y.float().to(device)\n",
    "        batch_y = batch_y.unsqueeze(dim=2)\n",
    "\n",
    "        batch_x_mark = batch_x_mark.float().to(device)\n",
    "        batch_y_mark = batch_y_mark.float().to(device)\n",
    "        \n",
    "        # decoder input\n",
    "        dec_inp = torch.zeros_like(batch_y[:, -configs.pred_len:, :]).float()\n",
    "        dec_inp = torch.cat([batch_y[:, :configs.label_len, :], dec_inp], dim=1).float().to(device)\n",
    "\n",
    "        # encoder - decoder\n",
    "        outputs, level, growths, seasons = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "        f_dim = -1 if configs.features == 'MS' else 0\n",
    "        batch_y = batch_y[:, -configs.pred_len:, f_dim:].to(device)\n",
    "        \n",
    "        return outputs, batch_y, level, growths, seasons\n",
    "        \n",
    "def vali(model, vali_data, vali_loader, criterion, configs):\n",
    "    total_loss = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(vali_loader):\n",
    "            outputs, batch_y, _, _, _ = run_iteration(model, batch_x, batch_y, batch_x_mark, batch_y_mark, device, configs)\n",
    "            \n",
    "            pred = outputs.detach().cpu()\n",
    "            true = batch_y.detach().cpu()\n",
    "\n",
    "            loss = criterion(pred, true)\n",
    "            total_loss.append(loss)\n",
    "\n",
    "    total_loss = np.average(total_loss)\n",
    "    model.train()\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1843f7b-f134-47bf-85a3-e3464c0e8f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('gs://pb-temp-gcs/datasets/traffic.csv')\n",
    "split_record = round(len(df)*0.8)\n",
    "df_train = df[:split_record]\n",
    "df_test = df[split_record:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f09ee39-3392-4119-b431-0175a47cfc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_provider(configs, dfname, shuffle):\n",
    "    timeenc = 0 if configs.embed != 'timeF' else 1\n",
    "\n",
    "    data_set = Dataset_Custom(\n",
    "        dfname,\n",
    "        size=[configs.seq_len, configs.label_len, configs.pred_len],\n",
    "        features=configs.features,\n",
    "        target=configs.target,\n",
    "        timeenc=timeenc,\n",
    "        freq=configs.freq\n",
    "    )\n",
    "    #print(flag, len(data_set))\n",
    "    data_loader = DataLoader(\n",
    "        data_set,\n",
    "        batch_size=configs.batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=configs.num_workers)\n",
    "    return data_set, data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f6807a7-0415-4679-ac32-ad8956eef54d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "    \n",
    "config = dotdict({\"d_model\":512,\"data\":\"custom\",\"seq_len\":336,\"features\":\"M\",\"pred_len\":96,\"e_layers\":2,\"d_layers\":2,\n",
    "                 \"enc_in\":862,\"dec_in\":862,\"c_out\":1,\"des\":\"Exp\",\"K\":3,\"learning_rate\":1e-3,\"itr\":1,\n",
    "                 \"dropout\":0.2, \"n_heads\":16, \"activation\":'sigmoid',\"target\":\"OT\", \"batch_size\":32,\n",
    "                 \"num_workers\":1, \"lradj\":\"exponential_with_warmup\", \"smoothing_learning_rate\":0,\n",
    "                 \"damping_learning_rate\":0, \"train_epochs\":10, \"warmup_epochs\":3,\n",
    "                 \"seq_len\":12,\"label_len\":0,\"pred_len\":12,\"use_gpu\":False, \"std\":0.2, \"min_lr\":1e-30,\n",
    "                 \"patience\":3})\n",
    "\n",
    "\n",
    "model = ETSformer(configs=config).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94cfb658-5b96-4de2-9843-83dc4d33f330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:132: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:132: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "/opt/conda/lib/python3.7/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:48: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\titers: 100, epoch: 1 | loss: 0.7712664\n",
      "\tspeed: 0.2316s/iter; left time: 991.6068s\n",
      "\titers: 200, epoch: 1 | loss: 0.6858945\n",
      "\tspeed: 0.2176s/iter; left time: 909.7735s\n",
      "\titers: 300, epoch: 1 | loss: 0.5359424\n",
      "\tspeed: 0.2189s/iter; left time: 893.3336s\n",
      "\titers: 400, epoch: 1 | loss: 0.4998950\n",
      "\tspeed: 0.2298s/iter; left time: 914.7044s\n",
      "Epoch: 1 cost time: 98.16027188301086\n",
      "Epoch: 1, Steps: 438 | Train Loss: 0.6687611 Vali Loss: 0.2572165\n",
      "Validation loss decreased (inf --> 0.257217).  Saving model ...\n",
      "Updating learning rate to 0.00025\n",
      "\titers: 100, epoch: 2 | loss: 0.1105455\n",
      "\tspeed: 0.3981s/iter; left time: 1529.8865s\n",
      "\titers: 200, epoch: 2 | loss: 0.0795861\n",
      "\tspeed: 0.2288s/iter; left time: 856.5746s\n",
      "\titers: 300, epoch: 2 | loss: 0.0090573\n",
      "\tspeed: 0.2186s/iter; left time: 796.2989s\n",
      "\titers: 400, epoch: 2 | loss: 0.0025555\n",
      "\tspeed: 0.2295s/iter; left time: 813.2865s\n",
      "Epoch: 2 cost time: 98.01407241821289\n",
      "Epoch: 2, Steps: 438 | Train Loss: 1.6217185 Vali Loss: 0.0005190\n",
      "Validation loss decreased (0.257217 --> 0.000519).  Saving model ...\n",
      "Updating learning rate to 0.0005\n",
      "\titers: 100, epoch: 3 | loss: 0.0005152\n",
      "\tspeed: 0.4009s/iter; left time: 1364.9682s\n",
      "\titers: 200, epoch: 3 | loss: 0.0005644\n",
      "\tspeed: 0.2290s/iter; left time: 756.9376s\n",
      "\titers: 300, epoch: 3 | loss: 0.0002790\n",
      "\tspeed: 0.2185s/iter; left time: 700.3254s\n",
      "\titers: 400, epoch: 3 | loss: 0.0005527\n",
      "\tspeed: 0.2186s/iter; left time: 678.7023s\n",
      "Epoch: 3 cost time: 97.36578726768494\n",
      "Epoch: 3, Steps: 438 | Train Loss: 0.0006069 Vali Loss: 0.0003723\n",
      "Validation loss decreased (0.000519 --> 0.000372).  Saving model ...\n",
      "Updating learning rate to 0.00075\n",
      "\titers: 100, epoch: 4 | loss: 0.0005125\n",
      "\tspeed: 0.4077s/iter; left time: 1209.6609s\n",
      "\titers: 200, epoch: 4 | loss: 0.0000913\n",
      "\tspeed: 0.2186s/iter; left time: 626.6027s\n",
      "\titers: 300, epoch: 4 | loss: 0.0001067\n",
      "\tspeed: 0.2285s/iter; left time: 632.2413s\n",
      "\titers: 400, epoch: 4 | loss: 0.0000792\n",
      "\tspeed: 0.2199s/iter; left time: 586.3650s\n",
      "Epoch: 4 cost time: 97.12891721725464\n",
      "Epoch: 4, Steps: 438 | Train Loss: 0.0002281 Vali Loss: 0.0002741\n",
      "Validation loss decreased (0.000372 --> 0.000274).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "\titers: 100, epoch: 5 | loss: 0.0001932\n",
      "\tspeed: 0.4142s/iter; left time: 1047.6048s\n",
      "\titers: 200, epoch: 5 | loss: 0.0001057\n",
      "\tspeed: 0.2177s/iter; left time: 528.7718s\n",
      "\titers: 300, epoch: 5 | loss: 0.0001198\n",
      "\tspeed: 0.2291s/iter; left time: 533.5590s\n",
      "\titers: 400, epoch: 5 | loss: 0.0001504\n",
      "\tspeed: 0.2303s/iter; left time: 513.3949s\n",
      "Epoch: 5 cost time: 100.39996266365051\n",
      "Epoch: 5, Steps: 438 | Train Loss: 0.0001376 Vali Loss: 0.0001551\n",
      "Validation loss decreased (0.000274 --> 0.000155).  Saving model ...\n",
      "Updating learning rate to 0.0005\n",
      "\titers: 100, epoch: 6 | loss: 0.0000987\n",
      "\tspeed: 0.4408s/iter; left time: 921.7360s\n",
      "\titers: 200, epoch: 6 | loss: 0.0000825\n",
      "\tspeed: 0.2313s/iter; left time: 460.4802s\n",
      "\titers: 300, epoch: 6 | loss: 0.0001173\n",
      "\tspeed: 0.2294s/iter; left time: 433.8662s\n",
      "\titers: 400, epoch: 6 | loss: 0.0000689\n",
      "\tspeed: 0.2364s/iter; left time: 423.4233s\n",
      "Epoch: 6 cost time: 103.44541454315186\n",
      "Epoch: 6, Steps: 438 | Train Loss: 0.0000939 Vali Loss: 0.0002333\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.00025\n",
      "\titers: 100, epoch: 7 | loss: 0.0000736\n",
      "\tspeed: 0.4186s/iter; left time: 691.8666s\n",
      "\titers: 200, epoch: 7 | loss: 0.0000818\n",
      "\tspeed: 0.2250s/iter; left time: 349.3846s\n",
      "\titers: 300, epoch: 7 | loss: 0.0000472\n",
      "\tspeed: 0.2223s/iter; left time: 323.0370s\n",
      "\titers: 400, epoch: 7 | loss: 0.0000698\n",
      "\tspeed: 0.2324s/iter; left time: 314.3856s\n",
      "Epoch: 7 cost time: 100.32242608070374\n",
      "Epoch: 7, Steps: 438 | Train Loss: 0.0000773 Vali Loss: 0.0001536\n",
      "Validation loss decreased (0.000155 --> 0.000154).  Saving model ...\n",
      "Updating learning rate to 0.000125\n",
      "\titers: 100, epoch: 8 | loss: 0.0000629\n",
      "\tspeed: 0.4039s/iter; left time: 490.7187s\n",
      "\titers: 200, epoch: 8 | loss: 0.0000953\n",
      "\tspeed: 0.2343s/iter; left time: 261.2912s\n",
      "\titers: 300, epoch: 8 | loss: 0.0001098\n",
      "\tspeed: 0.2236s/iter; left time: 226.9071s\n",
      "\titers: 400, epoch: 8 | loss: 0.0000653\n",
      "\tspeed: 0.2252s/iter; left time: 206.0925s\n",
      "Epoch: 8 cost time: 99.65770030021667\n",
      "Epoch: 8, Steps: 438 | Train Loss: 0.0000744 Vali Loss: 0.0001779\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0000658\n",
      "\tspeed: 0.4096s/iter; left time: 318.2279s\n",
      "\titers: 200, epoch: 9 | loss: 0.0000571\n",
      "\tspeed: 0.2317s/iter; left time: 156.8936s\n",
      "\titers: 300, epoch: 9 | loss: 0.0001006\n",
      "\tspeed: 0.2208s/iter; left time: 127.4198s\n",
      "\titers: 400, epoch: 9 | loss: 0.0000615\n",
      "\tspeed: 0.2197s/iter; left time: 104.8134s\n",
      "Epoch: 9 cost time: 98.09859561920166\n",
      "Epoch: 9, Steps: 438 | Train Loss: 0.0000688 Vali Loss: 0.0001669\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0000789\n",
      "\tspeed: 0.4115s/iter; left time: 139.5043s\n",
      "\titers: 200, epoch: 10 | loss: 0.0000605\n",
      "\tspeed: 0.2245s/iter; left time: 53.6550s\n",
      "\titers: 300, epoch: 10 | loss: 0.0000648\n",
      "\tspeed: 0.2365s/iter; left time: 32.8668s\n",
      "\titers: 400, epoch: 10 | loss: 0.0000788\n",
      "\tspeed: 0.2249s/iter; left time: 8.7702s\n",
      "Epoch: 10 cost time: 99.37219166755676\n",
      "Epoch: 10, Steps: 438 | Train Loss: 0.0000678 Vali Loss: 0.0001699\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import time\n",
    "import math\n",
    "path = \"./checkpoints\"\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "train_data, train_loader = data_provider(config, df_train, True)\n",
    "vali_data, vali_loader = data_provider(config, df_test, True)\n",
    "\n",
    "if config.use_gpu:\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "time_now = time.time()\n",
    "\n",
    "train_steps = len(train_loader)\n",
    "early_stopping = EarlyStopping(patience=config.patience, verbose=True)\n",
    "\n",
    "model_optim = select_optimizer(config,model)\n",
    "criterion = select_criterion()\n",
    "\n",
    "\n",
    "for epoch in range(config.train_epochs):\n",
    "    iter_count = 0\n",
    "    train_loss = []\n",
    "\n",
    "    model.train()\n",
    "    epoch_time = time.time()\n",
    "    for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(train_loader):\n",
    "        iter_count += 1\n",
    "        model_optim.zero_grad()\n",
    "\n",
    "        outputs, batch_y, _, _, _ = run_iteration(model, batch_x, batch_y, batch_x_mark, batch_y_mark, device, config)\n",
    "        \n",
    "        loss = criterion(outputs, batch_y)\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
    "            speed = (time.time() - time_now) / iter_count\n",
    "            left_time = speed * ((config.train_epochs - epoch) * train_steps - i)\n",
    "            print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
    "            iter_count = 0\n",
    "            time_now = time.time()\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n",
    "        model_optim.step()\n",
    "\n",
    "    print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n",
    "    train_loss = np.average(train_loss)\n",
    "    vali_loss = vali(model, vali_data, vali_loader, criterion, config)\n",
    "\n",
    "    print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f}\".format(\n",
    "        epoch + 1, train_steps, train_loss, vali_loss, vali_loss)) #last should be test_loss\n",
    "    early_stopping(vali_loss, model, path)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "    adjust_learning_rate(model_optim, epoch + 1, config)\n",
    "\n",
    "best_model_path = path + '/' + 'checkpoint.pth'\n",
    "model.load_state_dict(torch.load(best_model_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e78d0365-2dcb-4d9c-97ff-cc362c4533a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, batch_y, level, growths, seasons = run_iteration(model, batch_x, batch_y, batch_x_mark, batch_y_mark, device, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7afa384-87ee-4816-aad0-cada7d961dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:132: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "sample_df = df.iloc[:50]\n",
    "sample_data, sample_loader = data_provider(config, sample_df, False)\n",
    "for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(sample_loader):\n",
    "    outputs, y_hat, level, growths, seasons = run_iteration(model, batch_x, batch_y, batch_x_mark, batch_y_mark, device, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ddf8d7b-9275-4913-a78e-cff4c60aa8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 12, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b828d3b-d19d-44e5-acdf-13811c020a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2eb3ec57-c835-49c6-9adb-299fb75dae55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([15, 12])) that is different to the input size (torch.Size([15, 12, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (12) must match the size of tensor b (15) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10892/2183262170.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3259\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3261\u001b[0;31m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3262\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (12) must match the size of tensor b (15) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "criterion(outputs,batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf5c979-4bb2-40f2-8574-faa3b8172bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.squeeze()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdb1169-d2a0-42fc-9daf-aeed259c1635",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd755d1-6b1f-40b2-80f0-29099f541830",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs-batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51452e4-65c4-42f0-aeee-2444ca505a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test(self, setting, data, save_vals=False):\n",
    "    \"\"\"data - 'val' or 'test' \"\"\"\n",
    "    test_data, test_loader = self._get_data(flag=data)\n",
    "\n",
    "    print('loading model')\n",
    "    self.model.load_state_dict(torch.load(os.path.join('./checkpoints/' + setting, 'checkpoint.pth')))\n",
    "\n",
    "    preds = []\n",
    "    trues = []\n",
    "\n",
    "    self.model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(test_loader):\n",
    "            batch_x = batch_x.float().to(self.device)\n",
    "            batch_y = batch_y.float().to(self.device)\n",
    "\n",
    "            batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "            batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "            # decoder input\n",
    "            dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
    "            dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "            # encoder - decoder\n",
    "            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "            f_dim = -1 if self.args.features == 'MS' else 0\n",
    "            outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "            batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "            batch_y = batch_y.detach().cpu().numpy()\n",
    "\n",
    "            pred = outputs\n",
    "            true = batch_y\n",
    "\n",
    "            preds.append(pred)\n",
    "            trues.append(true)\n",
    "\n",
    "    preds = np.array(preds)\n",
    "    trues = np.array(trues)\n",
    "    print('test shape:', preds.shape, trues.shape)\n",
    "    preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "    trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n",
    "    print('test shape:', preds.shape, trues.shape)\n",
    "\n",
    "    # result save\n",
    "    folder_path = './results/' + setting + '/'\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    mae, mse, rmse, mape, mspe = metric(preds, trues)\n",
    "    print('mse:{}, mae:{}'.format(mse, mae))\n",
    "\n",
    "    np.save(folder_path + f'{data}_metrics.npy', np.array([mae, mse, rmse, mape, mspe]))\n",
    "\n",
    "    if save_vals:\n",
    "        np.save(folder_path + 'pred.npy', preds)\n",
    "        np.save(folder_path + 'true.npy', trues)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c86427-4fb8-47b7-8f51-f9ad4a01eec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
